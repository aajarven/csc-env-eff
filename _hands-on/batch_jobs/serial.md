---
topic: Batch jobs
title: Tutorial - Serial batch jobs
---

# Batch job tutorial - Serial jobs

> In this tutorial we'll get familiar with the basic usage of the Slurm batch queue system at CSC
- The goal is to learn how to request resources that **match** the needs of a job  

üí¨ A batch job consists of two parts: resource requests and the job step(s)

‚òùüèª Examples are done on Puhti 

## Serial jobs

üí¨ A serial program can use only one core (cpu)
    - One should request only one core from Slurm. 
    - The job doesn't benefit from additional cores
    - Excess reservation is wasted since it wouldn't be available to other users

üí¨ Within the job (or allocation), the actual program is launched using the command `srun` 

‚òùüèª If you use a software that is preinstalled at CSC, please [check its info-page](https://docs.csc.fi/apps/): it might have a batch job template with useful default settings

### Launching a serial job

1. Go to the scratch folder. 
    - Your input (and output) must be on a disk that is accessible on the compute node:
```bash
cd /scratch/project_XXXX         # replace XXXX
```
- You can list your projects with `csc-projects`). 
2. Create a file called `my_serial.bash` and copy the the following *batch script* there: 

```bash
#!/bin/bash
#SBATCH --account=project_xxx    # Choose the billing project. Has to be defined!
#SBATCH --time=00:02:00          # Maximum duration of the job. Max: depends of the partition. 
#SBATCH --partition=test         # Job queues: test, interactive, small, large, longrun, hugemem, hugemem_longrun
#SBATCH --ntasks=1               # Number of tasks. Max: depends on partition.

srun hostname                    # Run hostname-command in each task
srun sleep 60                    # Run sleep-command in each task
```  
üí¨ In the batch job example above we are requesting 
    - one core (`--ntasks=1`) 
    - for two minutes (`--time=00:02:00`) 
    - from the test queue (`--partition=test`)  
üí¨ We want to run the program `hostname`, that will print the name of the Puhti computing node that has been allocated for this particular job.
- In addition, we are running the `sleep` program to keep the job running for an additional 60 seconds, in order to have time to monitor the job  
3. Change the `project_xxx` to the project you actually want to use (e.g. with `nano`)
- Submit the job to the queue and then check the queue with the commands:
```bash
sbatch my_serial.bash
squeue -u $USER
``` 

### Checking the output and the efficiency
- By default the output is written into a file named `slurm-XXXXXXX.out` where `XXXXXXX` is the unique job ID
- Check the efficiency of the job compared to the reserved resources by issuing the command `seff XXXXXXX` (replace `XXXXXXX` with the job ID number from the `slurm-XXXXXXX.out` file) 

üí≠ You can get a list of all your jobs that are running or queuing with the command `squeue -u $USER`  
üóØ A submitted job can be cancelled using the command `scancel XXXXXXX` 

### Additional material [FAQ on CSC batch jobs ](https://docs.csc.fi/support/faq/#batch-jobs) in Docs CSC